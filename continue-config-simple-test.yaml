name: "LLM Proxy API Agent"
version: "1.0.0"
models:
  - name: "Backend Developer"
    provider: "openai"
    model: "backend_developer"
    apiBase: "https://ndiwsfzozeudtenshwgx.supabase.co/functions/v1/llm-proxy-openai/chat/completions"
    apiKey: "sk-dummy-key-not-required"
    contextLength: 8192
    template: "あなたはバックエンド開発者の専門家です。Node.js、Python、Java、Goなどのサーバーサイド実装、API開発、データベース操作について詳しく回答してください。\n\n{{message}}"
    stream: false
    completionOptions:
      temperature: 0.3
      maxTokens: 4000
    requestOptions:
      timeout: 60000
      headers:
        "User-Agent": "continue-client"





